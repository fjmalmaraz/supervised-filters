# ESAI-CEU-UCH Supervised Filters for epilepsy 

This work presents  preprocessing methods to improve KNN
performance. These scripts are based on the [solution proposed by Universidad CEU Cardenal Herrera
(ESAI-CEU-UCH)](https://github.com/ESAI-CEU-UCH/kaggle-epilepsy) at Kaggle American Epilepsy Society Seizure Prediction
Challenge. The proposed solution was positioned as **4th (3rd prize)** at
[Kaggle competition](https://www.kaggle.com/c/seizure-prediction).

These scripts allow a comparison between raw features using
conventional techniques and the features preprocessed with DS filter.

It is important to note that **any** of the proposed systems use test set for
calibration. The competition allow to do this model calibration using test set,
but doing it will reduce the reproducibility of the results in a real world
implementation.

# Dependencies

## Software

This solution uses the following open source software:

- [APRIL-ANN](https://github.com/pakozm/april-ann) toolkit v0.4.0. It is a
  toolkit for pattern recognition with Lua and C/C++ core. Because this tool is
  very new, the installation and configuration has been written in the pipeline.
- [R project](http://www.r-project.org/) v3.0.2. For statistical computing, a
  wide spread tool in Kaggle competitions. Packages R.matlab, MASS, fda.usc,
  fastICA, stringr and plyr are necessary to run the solution.
- [GNU BASH](http://www.gnu.org/software/bash/) v4.3.11, with cp, mv, find,
  mktemp, sort and tr command line tools.

The solution is prepared to run in a Linux platform with
[Ubuntu 14.04 LTS](http://www.ubuntu.com/), but it could run in other Debian
based distributions, but not tested.

Additionally, APRIL-ANN toolkit has been compiled using the
[Intel MKL library](https://software.intel.com/en-us/intel-mkl), and it is
needed to ensure reproducibility of ANN models in the solution. However, the
delivered code revision uses by default ATLAS library, which is open source and
standard in Linux systems, but it can also be configured to use Intel MKL
library.

## Hardware

The minimum requirements for the correct execution of this software are:

- 6GB of RAM.
- 1.5GB of disk space.

The experimentation has been performed in a cluster of **three** computers
with same hardware configuration:

- Server rack Dell PowerEdge 210 II.
- Intel Xeon E3-1220 v2 at 3.10GHz with 16GB RAM (4 cores).
- 2.6TB of NFS storage.

# How to generate the solution

The solution can be generated by executing bash-scripts located at the
repository root folder. 

## General settings

The configuration of the input data, subjects, and other stuff is in
`settings.sh` script. The following environment variables indicate the location
of data and result folders:

- `DATA_PATH=DATA` indicates where the original data is. It will be organized in
  subfolders, one for each available subjects, and this subfolders will contain
  the corresponding MAT files.
- `TMP_PATH=TMP` indicates the folder for intermediate results (feature extraction).
- `MODELS_PATH=MODELS` indicates the folder where models training and results
  are stored.
- `SUBMISSIONS_PATH=SUBMISSIONS` indicates where test results will be generated.
- `USE_MKL=0` change this flag to indicate that you want to compile APRIl-ANN
  using Intel MKL library.

All other environment variables are computed depending on these root paths.
Note that all the solution must be executed being in the root path of the git
repository. The list of available subjects depends on the subfolders of
`$DATA_PATH`.

## Recipe to reproduce the solution

It is possible to train and test two selected submissions by executing the
script `train.sh`:

```
$ ./train.sh
```

It generates intermediate files in `$TMP_PATH` folder. First, all the proposed
features are generated to disk:

1. `$TMP_PATH/FFT_60s_30s_BFPLOS` contains FFT filtered features using 1 min. windows.
2. `$TMP_PATH/FFT_60s_30s_COMPRESS/` contains the compressed FFT signal.
3. `$TMP_PATH/FFT_60s_30s_DS/` contains the tranformation of FFT by
   means of DS filter.

This preprocess can be executed without training by using the script
`preprocess.sh`.

Once preprocessing step is ready, training of the proposed models starts. The
model results are stored in subfolders of `$MODELS_PATH`. This subfolders contain
similar data:

- `validation_SUBJECT.txt` is the concatenation of cross-validation output, used
  to optimize the final ensemble.
- `validation_SUBJECT.test.txt` is the test results corresponding to the
  indicated subject (without CSV header).
- `test.txt` is the concatenation of all test results with the CSV header needed
  to send it as submission to Kaggle.

The trained systems are stored at folders:

1. `$MODELS_PATH/KNN_PBF_RESULT`
2. `$MODELS_PATH/KNN_PBF_RESULT`


Finally, confidence interval for AUC and a comparison of the AUC
values using hypothesis testing are perform.

## Recipe to train a new subject

In order to train a new subject, you can use `train_subject.sh` script, which
receives as argument the name of the subject:

```
$ ./train_subject.sh SUBJECT_NAME
```
